{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'YetiUtils' from '/mnt/booleanfs2/sahoo/Data/BooleanLab/Yotam/YetiUtils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import ast\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import YetiUtils as yeti\n",
    "try:\n",
    "    reload  # Python 2.7\n",
    "except NameError:\n",
    "    try:\n",
    "        from importlib import reload  # Python 3.4+\n",
    "    except ImportError:\n",
    "        from imp import reload  # Python 3.0 - 3.3\n",
    "reload(yeti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "confPath='/Users/yovosko/public_html/Hegemon/explore.conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeConfDict(confPath='/Users/yovosko/public_html/Hegemon/explore.conf',skipTest=True,overWrite=False):\n",
    "    \"\"\"\n",
    "    makeConfDict\n",
    "        Inputs:\n",
    "            confPath: str or list (of strs), path to explore.conf file wanted information, \n",
    "                            can also be a list of multiple paths to multiple explore.conf files \n",
    "            skipTest, boolean, if True will skip the Test dataset (T1) in the confPath file\n",
    "                    default: True\n",
    "            overWrite: boolean, if mulitple instances of the same id, \n",
    "                            if True will overwrite with the newest dataset\n",
    "                            if False will not overwrite and keep first dataset instance\n",
    "                            deafult: False\n",
    "        Outputs:\n",
    "            dictionary with all the information about all the datasets in confPath file\"\"\"\n",
    "    confDict={}\n",
    "    if type(confPath) is list:\n",
    "        confPathLst=confPath\n",
    "    else:\n",
    "        confPathLst=[confPath]\n",
    "    for confPathIn in confPathLst:\n",
    "        with open(confPathIn) as f:\n",
    "            for line in f:\n",
    "                if '[' in line:\n",
    "                    idd=line.split(']')[0].split('[')[1]\n",
    "                    if idd in confDict and not overWrite:\n",
    "                        idd=''\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]={}\n",
    "                if 'name' in line and '=' in line:\n",
    "                    name=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Name']=name\n",
    "                if 'expr' in line and '=' in line:\n",
    "                    expr=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Expr']=expr\n",
    "                if 'index' in line and '=' in line:\n",
    "                    index=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Index']=index\n",
    "                if 'survival' in line and '=' in line:\n",
    "                    survival=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Survival']=survival\n",
    "                if 'indexHeader' in line and '=' in line:\n",
    "                    indexheader=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['IndexHeader']=indexheader\n",
    "                if 'info' in line and '=' in line:\n",
    "                    info=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Info']=info\n",
    "                if 'key' in line and '=' in line:\n",
    "                    keys=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Keys']=keys\n",
    "                if 'source' in line and '=' in line:\n",
    "                    gse=line.split('=')[-1].split('\\n')[0].strip()\n",
    "                    if not skipTest or not idd=='T1':\n",
    "                        confDict[idd]['Source']=gse\n",
    "    return confDict\n",
    "\n",
    "def getValueFromConfDict(value='Source',idd='All',confDict={},returnType='dict',\n",
    "                         confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    \"\"\"\n",
    "    getValueFromConfDict\n",
    "        Inputs:\n",
    "            value, str, value key that has info wanted, default='Source\n",
    "            idd, str, Id of dataset with the wanted info, \n",
    "                default='All'\n",
    "                if 'All' will return dictionary or list of values for all dataset, \n",
    "                    with the dataset Ids as the keys of the dictionary if returnType=='dict'\n",
    "                    and a list of the unique values if returnType=='list'\n",
    "            confDict, dictionary, dictionary with info for datasets in confPath file, \n",
    "                default={}\n",
    "                if confDict is empty will create a new one from confPath (will increase total runtime)\n",
    "                to save runtime use makeConfDict() to create a confDict beforehand\n",
    "            returnType, str, if idd=='All' then tells if to return info as a dictionary or a list of the values,\n",
    "                default='dict'\n",
    "                curently only works if input is either 'list' or 'dict'\n",
    "            confPath, str, path to explore.conf file to be used if not given confDict, \n",
    "                default='/Users/yovosko/public_html/Hegemon/explore.conf'\n",
    "        Output:\n",
    "            the information for the selected value for the dataset selected in idd\n",
    "            or a dictionary/list of those values if idd='All'\n",
    "    '\"\"\"\n",
    "    if len(confDict)==0:\n",
    "        confDict=makeConfDict(confPath)\n",
    "    if idd=='All':\n",
    "        if returnType=='dict':\n",
    "            val={}\n",
    "        elif returnType=='list':\n",
    "            val=set()\n",
    "        for i in list(confDict.keys()):\n",
    "            if value in confDict[i]:\n",
    "                val1=confDict[i][value]\n",
    "            else:\n",
    "                val1=''\n",
    "            if returnType=='dict':\n",
    "                val[i]=val1\n",
    "            elif returnType=='list':\n",
    "                val.add(val1)\n",
    "        if returnType=='list':\n",
    "            val=list(val)\n",
    "    else:\n",
    "        val=confDict[idd][value]\n",
    "    return val\n",
    "\n",
    "def getDatasetExpressionFile(idd,confDict={},returnType='dict',\n",
    "                             confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='Expr',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)\n",
    "\n",
    "def getDatasetIndexFile(idd,confDict={},returnType='dict',\n",
    "                        confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='Index',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)\n",
    "\n",
    "def getDatasetSurvivalFile(idd,confDict={},returnType='dict',\n",
    "                           confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='Survival',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)\n",
    "\n",
    "def getDatasetIndexHeaderFile(idd,confDict={},returnType='dict',\n",
    "                              confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='IndexHeader',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)\n",
    "\n",
    "def getDatasetInfoFile(idd,confDict={},returnType='dict',\n",
    "                       confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='Info',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)\n",
    "\n",
    "def getDatasetKeys(idd,confDict={},returnType='dict',\n",
    "                   confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='Keys',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)\n",
    "\n",
    "def getDatasetSource(idd,confDict={},returnType='dict',\n",
    "                     confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    return getValueFromConfDict(value='Source',idd=idd,confDict=confDict,confPath=confPath,returnType=returnType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetIdFromSource(source,confDict={},confPath='/Users/yovosko/public_html/Hegemon/explore.conf'):\n",
    "    \"\"\"\n",
    "    getDatasetIdFromSource\n",
    "        Inputs:\n",
    "            source, str, source which you want to get the Id for\n",
    "            confDict, dictionary, dictionary with info for datasets in confPath file, \n",
    "                default={}\n",
    "                if confDict is empty will create a new one from confPath (will increase total runtime)\n",
    "                to save runtime use makeConfDict() to create a confDict beforehand\n",
    "            confPath, str, path to explore.conf file to be used if not given confDict, \n",
    "                default='/Users/yovosko/public_html/Hegemon/explore.conf'\n",
    "        Output:\n",
    "            returns a list of all dataset Ids that have data from that source \n",
    "            will include datasets which have data from multiple sources if source is one of them\n",
    "    \"\"\"\n",
    "    if len(confDict)==0:\n",
    "        confDict=makeConfDict(confPath)\n",
    "    out=[]\n",
    "    for i in confDict.keys():\n",
    "        if 'Source' in confDict[i]:\n",
    "            source1=confDict[i]['Source'].split(' ')\n",
    "            if source in source1:\n",
    "                out.append(i)\n",
    "    if len(out)==0:\n",
    "        print('Source '+source+' not in this explore.conf file, check if you gave the correct confPath, and try setting confDict={}')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEMtabData(emtab,confDict,verbose=True):\n",
    "    \"\"\"getEMtabData\n",
    "        Inputs:\n",
    "            emtab, str, accession id for a uk biostudies dataset\n",
    "        Output:\n",
    "            return the E-M-tab  dataset acession id, # of samples, species, \n",
    "                    experiment type,tissue dict, age dict, sex dict and citation\n",
    "    \"\"\"\n",
    "    urlBase='https://www.ebi.ac.uk/biostudies/files/'\n",
    "    url=urlBase+emtab+'/'+emtab+'.json'\n",
    "    r = requests.get(url)\n",
    "    text = r.text\n",
    "    species=text.split('\"Organism\",\\n')[1].split('\\n')[0].split(':')[-1].strip().replace('\"','')\n",
    "    samNum=int(text.split('Sample count\",\\n')[-1].split('\\n')[0].split(':')[-1].strip().replace('\"',''))\n",
    "    if 'PMID' in text:\n",
    "        ref=text.split('PMID\",\\n')[-1].split('\\n')[0].split(':')[-1].strip().replace('\"','')\n",
    "        \n",
    "        refId=ref.split('/')[-1]\n",
    "        urlBase2='https://pubmed.ncbi.nlm.nih.gov/'\n",
    "        url=urlBase2+refId\n",
    "        r2 = requests.get(url)\n",
    "        text2 = str(r2.content)\n",
    "        doi=text2.split('doi:')[1].split(',')[0]\n",
    "        citation = 'https://doi.org/'+doi\n",
    "    else:\n",
    "        if emtab=='E-MTAB-1788':\n",
    "            citation='https://doi.org/10.1186/s13395-015-0059-1'\n",
    "        elif emtab=='E-MEXP-740':\n",
    "            citation='https://doi.org/10.1093/gerona/62.10.1088'\n",
    "        else:\n",
    "            citation='Missing'\n",
    "    exprType=text.split('\"Study type\",\\n')[1].split('\\n')[0].split(':')[-1].strip().replace('\"','').replace(',','')\n",
    "    tissues,genders,ages,vo2,dieases,times,trains=getTissSexAge(emtab,confDict,verbose=verbose)\n",
    "    return emtab,samNum,species,exprType,tissues,genders,ages,vo2,diseases,times,trains,citation \n",
    "\n",
    "\n",
    "\n",
    "def getGSEData(gse,confDict={},verbose=True):\n",
    "    \"\"\"getGSEData\n",
    "        Inputs:\n",
    "            gse, str, accession id for a gene expression omnibus or uk biostudies dataset\n",
    "            confDict, dictionary, dictionary of processed datasets, if not porcessed will be ignored\n",
    "                    default: {}\n",
    "            verbose, boolean, if True will print out non-error messages\n",
    "                    default:True\n",
    "        Output:\n",
    "            return the dataset acession id, # of samples, species, tissue dict, age dict, sex dict and citation\n",
    "    \"\"\"\n",
    "    if 'GSE' in gse:\n",
    "        urlBase='https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc='\n",
    "        url=urlBase+gse\n",
    "        r = requests.get(url)\n",
    "        text = str(r.content)\n",
    "        numSamples=getNumSamplesGSE(text,gse)\n",
    "        species = text.split('geoaxema_organismus')[-1].split('>')[1].split('<')[0]\n",
    "        try:\n",
    "            experType=text.split('Experiment type')[1].split('>')[2].split('<')[0]\n",
    "        except:\n",
    "            experType='unk' \n",
    "        if len(confDict)>0:\n",
    "            tissues,ages,genders,vo2,diseases,times,trains=getTissSexAge(gse,confDict=confDict,verbose=verbose)\n",
    "        else:\n",
    "            tissues={};genders={};ages={};vo2={};dieases={};times={};trains={}\n",
    "        citation=getCitationGSE(gse,text)\n",
    "    elif 'E-MTAB' in gse or 'E-MEXP' in gse:\n",
    "        gse,numSamples,species,experType,tissues,genders,ages,vo2,dieases,times,trains,citation=getEMtabData(gse,\n",
    "                                                                                                             confDict=confDict,\n",
    "                                                                                                             verbose=verbose)\n",
    "    else:\n",
    "        raise TypeError('Non GSE files not currently supported')\n",
    "    return gse,numSamples,species,experType,tissues,genders,ages,vo2,dieases,times,trains,citation\n",
    "\n",
    "def getNumSamplesGSE(text,gse):\n",
    "    if gse=='GSE123878':\n",
    "        numSamples=87\n",
    "    elif gse=='GSE151066':\n",
    "        numSamples=57\n",
    "    else:\n",
    "        numSamples=text.split('Samples')[-1].split(')')[0].split('(')[1]\n",
    "        numSamples=int(numSamples)\n",
    "    return numSamples\n",
    "\n",
    "def getCitationGSE(gse,text):\n",
    "    hasCitation=text.split('Citation')[1].split('<')[0]\n",
    "    if hasCitation == ' missing':\n",
    "        citation='Missing'\n",
    "        if gse=='GSE68585':\n",
    "            citation='https://doi.org/10.1371/journal.pone.0160327'\n",
    "        if gse=='GSE126001':\n",
    "            citation='https://doi.org/10.1126/science.aat3987'\n",
    "        if gse=='GSE83578':   \n",
    "            citation='http://doi.org/10.1186/s12974-016-0758-5'\n",
    "        if gse=='GSE4252':\n",
    "            citation='https://doi.org/10.1096/fj.04-3149fje'\n",
    "        if gse=='GSE23697':\n",
    "            citation='https://doi.org/10.1249/01.MSS.0000384251.51943.52'\n",
    "        if gse=='GSE111212':   \n",
    "            citation='https://doi.org/10.3390/cells11233864'\n",
    "        if gse=='GSE93546':\n",
    "            citation='https://doi.org/10.1096/fj.201900453R'\n",
    "        if gse=='GSE221210':\n",
    "            citation='https://doi.org/10.1038/s42255-023-00891-y'\n",
    "        if gse=='GSE111555':\n",
    "            citation='https://doi.org/10.1002/lipd.12155'\n",
    "    else:\n",
    "        ref=text.split('Citation')[1].split('href=')[1].split('\"')[1]\n",
    "        if 'pubmed' in ref:\n",
    "            refId=ref.split('/')[-1]\n",
    "            urlBase2='https://pubmed.ncbi.nlm.nih.gov/'\n",
    "            url=urlBase2+refId\n",
    "            r2 = requests.get(url)\n",
    "            text2 = str(r2.content)\n",
    "            doi=text2.split('doi:')[1].split(',')[0]\n",
    "            citation = 'https://doi.org/'+doi\n",
    "        else:\n",
    "            if 'http' in ref:\n",
    "                citation=ref\n",
    "                citation=citation.replace('/dx.','/')\n",
    "            elif 'doi' in text:\n",
    "                doi=text.split('Citation')[1].split('doi:')[1].split('<')[0]\n",
    "                citation='https://doi.org/'+doi\n",
    "            else:\n",
    "                citation=ref\n",
    "    return citation\n",
    "\n",
    "def getDataDf(dataFiles,save=False,saveName='TodoDatasets.csv',confDict={},verbose=True):\n",
    "    dfDict={}\n",
    "    for i in tq(dataFiles):\n",
    "        if 'GSE' in i or 'E-MTAB' in i or 'EMTAB' in i or 'EMEXP' in i or 'E-MEXP' in i:\n",
    "            try:\n",
    "                out=getGSEData(i,confDict=confDict,verbose=verbose)\n",
    "                lst=[i for i in out]\n",
    "                dfDict[i]=lst\n",
    "            except Exception as error:\n",
    "                print('Error on '+str(i),error)\n",
    "        else:\n",
    "            print(\"Didn't try: \"+i+', not currently supported')\n",
    "    df=pd.DataFrame(dfDict)\n",
    "    df=df.T\n",
    "    df.columns=['ID','Number Samples','Species','Experiment Type','Tissues','Genders','Ages','Vo2','Disease','Citation']\n",
    "    df=df.sort_values(by='ID',ascending=True)\n",
    "    if save:\n",
    "        df.to_csv(saveName)\n",
    "    return df\n",
    "\n",
    "def __shouldIRunTissGenderAge(surv):\n",
    "    \"\"\"\n",
    "    __shouldIRunTissGenderAge\n",
    "        Inputs:\n",
    "            surv, dataframe, survival file with info on tissue/age/gender of samples\n",
    "        Output:\n",
    "            returns True if there are columns in surv that include tissue/age/gender info, False if not\n",
    "                If True will also give the names of the columns in surv with that info\n",
    "    \"\"\"\n",
    "    tissueCol='';ageCol='';genderCol='';vo2Col='';diseaseCol='';timeCol='';trainCol=''\n",
    "    for i in surv.columns:\n",
    "        i2=i.replace('Age','age').replace('Tissue','tissue').replace('Sex','sex').replace('Gender','gender')\n",
    "        i2=i2.replace('VO2','vo2').replace('Vo2','vo2').replace('vO2','vo2').replace('Disease','disease')\n",
    "        i2=i2.replace('VO 2','vo2').replace('vO 2','vo2').replace('Vo 2','vo2')\n",
    "        i2=i2.replace('Time','time').replace('Training','training')\n",
    "        if 'age' in i2:\n",
    "            ageCol=i\n",
    "            continue\n",
    "        if 'tissue' in i2:\n",
    "            tissueCol=i\n",
    "            continue\n",
    "        if 'sex' in i2:\n",
    "            genderCol=i\n",
    "            continue\n",
    "        if 'gender' in i2:\n",
    "            genderCol=i\n",
    "            continue\n",
    "        if 'max' in i2:\n",
    "            vo2Col=i\n",
    "            continue\n",
    "        if 'vo2' in i2:\n",
    "            vo2Col=i\n",
    "            continue\n",
    "        if 'disease' in i2:\n",
    "            diseaseCol=i\n",
    "            continue\n",
    "        if 'time' in i2 and 'c' in i2:\n",
    "            timeCol=i\n",
    "        if 'training' in i2:\n",
    "            trainCol=i\n",
    "    if tissueCol!='' or ageCol!='' or genderCol!='' or vo2Col!='' or diseaseCol!='' or timeCol!='' or trainCol!='':\n",
    "        return True,tissueCol,ageCol,genderCol,vo2Col,diseaseCol,timeCol,trainCol\n",
    "    else:\n",
    "        return False,tissueCol,ageCol,genderCol,vo2Col,diseaseCol,timeCol,trainCol\n",
    "\n",
    "def getTissSexAge(gse,confDict,verbose=True):\n",
    "    ids=getDatasetIdFromSource(gse,confDict)\n",
    "    if len(ids)>1:\n",
    "        if verbose:\n",
    "            print('multi id',gse,ids)\n",
    "        maxSams=-1\n",
    "        for idd in ids:\n",
    "            if not 'MUSCLE' in idd:\n",
    "                survival_file=getDatasetSurvivalFile(idd,confDict=confDict)\n",
    "                surv=pd.read_csv(survival_file,sep='\\t',index_col=0)\n",
    "                sams=set(surv.index)\n",
    "                if len(sams)>maxSams:\n",
    "                    maxSams=len(sams)\n",
    "                    finSurv=surv\n",
    "        surv=finSurv\n",
    "    else:\n",
    "        idd=ids[0]\n",
    "        survival_file=getDatasetSurvivalFile(idd,confDict=confDict)\n",
    "        surv=pd.read_csv(survival_file,sep='\\t',index_col=0)\n",
    "    run,tissueCol,ageCol,genderCol,vo2Col,diseaseCol,timeCol,trainCol = __shouldIRunTissGenderAge(surv)\n",
    "    if run:\n",
    "        tissDict,ageDict,genderDict,vo2Dict,diseaseDict,timeDict,trainDict=__getTissGenderAgeHelper(surv,\n",
    "                                                                                                    tissueCol=tissueCol,\n",
    "                                                                                                    ageCol=ageCol,\n",
    "                                                                                                    genderCol=genderCol,\n",
    "                                                                                                    vo2Col=vo2Col,\n",
    "                                                                                                    diseaseCol=diseaseCol,\n",
    "                                                                                                    timeCol=timeCol,\n",
    "                                                                                                    trainCol=trainCol)\n",
    "    else:\n",
    "        tissDict={};ageDict={};genderDict={};vo2Dict={};diseaseDict={};timeDict={};trainDict={}\n",
    "    return tissDict,ageDict,genderDict,vo2Dict,diseaseDict,timeDict,trainDict\n",
    "\n",
    "def __getTissGenderAgeHelper(surv,tissueCol,ageCol,genderCol,vo2Col,diseaseCol,timeCol,trainCol):\n",
    "    tissDict={};ageDict={};genderDict={};vo2Dict={};diseaseDict={};timeDict={};trainDict={}\n",
    "    if tissueCol!='':\n",
    "        tissLst=list(surv[tissueCol])\n",
    "        for i in set(tissLst):\n",
    "            if type(i) is not float:\n",
    "                j=i.capitalize()\n",
    "            else:\n",
    "                j=i\n",
    "            if j in tissDict:\n",
    "                tissDict[j]+=tissLst.count(i)\n",
    "            else:\n",
    "                tissDict[j]=tissLst.count(i)\n",
    "    if ageCol!='':\n",
    "        ageLst=list(surv[ageCol])\n",
    "        for i in set(ageLst):\n",
    "            ageDict[i]=ageLst.count(i)\n",
    "    if genderCol!='':\n",
    "        genderLst=list(surv[genderCol])\n",
    "        for i in set(genderLst):\n",
    "            if type(i) is not float:\n",
    "                j=i.split(' ')[0].capitalize()\n",
    "                j=j.replace('Female','F').replace('Male',\"M\").replace('Mixed','mixed')\n",
    "                j=j.replace('M','Male').replace('F','Female').replace('mixed','Mixed')\n",
    "            else:\n",
    "                j=i\n",
    "            if j in genderDict:\n",
    "                genderDict[j]+=genderLst.count(i)\n",
    "            else:\n",
    "                genderDict[j]=genderLst.count(i)\n",
    "    if vo2Col!='':\n",
    "        vo2Lst=list(surv[vo2Col])\n",
    "        for i in set(vo2Lst):\n",
    "            vo2Dict[i]=vo2Lst.count(i)\n",
    "    if diseaseCol!='':\n",
    "        diseaseLst=list(surv[diseaseCol])\n",
    "        for i in set(diseaseLst):\n",
    "            j=i.capitalize()\n",
    "            if j in diseaseDict:\n",
    "                diseaseDict[j]+=diseaseLst.count(i)\n",
    "            else:\n",
    "                diseaseDict[j]=diseaseLst.count(i)\n",
    "    if timeCol!='':\n",
    "        timeLst=list(surv[timeCol])\n",
    "        for i in set(timeLst):\n",
    "            timeDict[i]=timeLst.count(i)\n",
    "    if trainCol!='':\n",
    "        trainLst=list(surv[trainCol])\n",
    "        for i in set(trainLst):\n",
    "            trainDict[i]=trainLst.count(i)\n",
    "    return tissDict,ageDict,genderDict,vo2Dict,diseaseDict,timeDict,trainDict\n",
    "\n",
    "def readDataFrameFile(file,index_col=None,header=0,sep=None,convertDicts=False,dictLst=['Tissues','Ages','Genders']):\n",
    "    \"\"\"Inputs:\n",
    "        file, str, name of path to input file\n",
    "        index_col, int/None, number of column to be used as index, default = None\n",
    "        header, int, number of row to be used as header/first row, deafult = 0\n",
    "        sep, str, if the name of the file does not conventionally match its seperation\n",
    "            example: file is .txt but seperator is ' ', default = None\n",
    "    Output:\n",
    "        pandaas dataframe of the inputed file (currently only supports csv, tsv/txt and xlsx files)\"\"\"\n",
    "    if '.xlsx' in file:\n",
    "        df=pd.read_excel(file,index_col=index_col,header=header)\n",
    "    else:\n",
    "        if '.csv' in file:\n",
    "            sepF=','\n",
    "        elif '.tsv' in file or '.txt' in file:\n",
    "            sepF='\\t'\n",
    "        else:\n",
    "            raise ValueError('File type currently not supported, please use either a .csv, .tsv, .txt or .xlsx file')\n",
    "        if sep is None:\n",
    "            sep=sepF\n",
    "        df=pd.read_csv(file,sep=sep,index_col=index_col,header=header)\n",
    "    if convertDicts:\n",
    "        for i in df.index:\n",
    "            for j in dictLst:\n",
    "                string=df.at[i,j].replace('nan','\"\"')\n",
    "                res = ast.literal_eval(string)\n",
    "                df.at[i,j]=res\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "confPathLst=['/Users/yovosko/public_html/Hegemon/explore.conf','/booleanfs2/sahoo/Hegemon/explore.conf',\n",
    "             \"/Users/aglina/public_html/Hegemon/explore.conf\"]\n",
    "\n",
    "confDict=makeConfDict(confPathLst)\n",
    "gsmLst=getDatasetSource(idd='All',confDict=confDict,returnType='list')\n",
    "conf=[c for c in gsmLst if not '/' in c]\n",
    "conf2=[c for c in conf if c!='']\n",
    "conf3=[c for c in gsmLst if '/' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prePost=pd.read_csv('Macrophages_Pre_Post.txt',sep='\\t',index_col=0)\n",
    "sedEx=pd.read_csv('Macrophages_Sed_Ex.txt',sep='\\t',index_col=0)\n",
    "\n",
    "prePost['Exercise Type']='Immediate'\n",
    "sedEx['Exercise Type']='Training'\n",
    "\n",
    "exerciseDf=pd.concat([prePost,sedEx])\n",
    "\n",
    "gses=list(exerciseDf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gses.remove('GSE86931')\n",
    "gses.remove('GSE1718')\n",
    "gses.remove('GSE5105')\n",
    "gses.append('GSE3606')\n",
    "gses=[i.replace('EMTAB','E-MTAB-').replace('EMEXP','E-MEXP-') for i in gses]\n",
    "gses=list(set(gses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b25040e56cc4cf384b8e25df784f899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='GSES', max=76.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi id E-MTAB-1788 ['MSL1', 'MSL2']\n",
      "multi id GSE104079 ['M6', 'MUSCLE8']\n",
      "multi id GSE11803 ['M21-0', 'MUSCLE9']\n",
      "multi id GSE126296 ['M2', 'MUSCLE11']\n",
      "multi id GSE139258 ['M33', 'MUSCLE12']\n",
      "multi id GSE155933 ['M002', 'MUSCLE3', 'M1-2']\n",
      "multi id GSE230102 ['M105-0', 'M105-1']\n",
      "multi id GSE242354 ['MUSL79-0', 'MUSL79-1']\n",
      "multi id GSE44051 ['M23', 'MUSCLE7']\n",
      "multi id GSE68072 ['MB7', 'MUSCLE16']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tissLst=[];ageLst=[];gendLst=[];vo2Lst=[];disLst=[];timeLst=[];trainLst=[]\n",
    "for gse in tq(dataDf.index,'GSES'):\n",
    "    tissues,ages,genders,vo2s,diseases,times,trains=getTissSexAge(gse,confDict=confDict,verbose=True)\n",
    "    tissLst.append(tissues)\n",
    "    ageLst.append(ages)\n",
    "    gendLst.append(genders)\n",
    "    vo2Lst.append(vo2s)\n",
    "    disLst.append(diseases)\n",
    "    timeLst.append(times)\n",
    "    trainLst.append(trains)\n",
    "    \n",
    "dataDf['Tissues']=tissLst\n",
    "dataDf['Ages']=ageLst\n",
    "dataDf['Genders']=gendLst\n",
    "dataDf['Vo2']=vo2Lst\n",
    "dataDf['Diseases']=disLst\n",
    "dataDf['Time Points']=timeLst\n",
    "dataDf['Trainings']=trainLst\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf.to_excel('MacrophageExercise_DatasetsInfo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoFile='MacrophageExercise_DatasetsInfo.xlsx'\n",
    "#try:\n",
    "dataDf=readDataFrameFile(infoFile,convertDicts=True,index_col=0,\n",
    "                         dictLst=['Tissues','Ages','Genders','Time Points','Vo2','Diseases','Trainings'])\n",
    "#except:\n",
    "#    dataDf=getDataDf(gses,save=True,saveName=infoFile,confDict=confDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDf.to_excel('MacrophageExercise_DatasetsInfo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TrainingsDatasets.txt'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gendLst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Genders'])>1:\n",
    "        gendLst.append(i)\n",
    "yeti.saveLst(gendLst,'GendersDatasets.txt')\n",
    "\n",
    "ageLst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Ages'])>1:\n",
    "        ageLst.append(i)\n",
    "yeti.saveLst(ageLst,'AgesDatasets.txt')\n",
    "\n",
    "vo2Lst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Vo2'])>1:\n",
    "        vo2Lst.append(i)\n",
    "yeti.saveLst(vo2Lst,'Vo2Datasets.txt')\n",
    "\n",
    "disLst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Diseases'])>1:\n",
    "        disLst.append(i)\n",
    "yeti.saveLst(disLst,'DiseaseDatasets.txt')\n",
    "\n",
    "tissLst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Tissues'])>1:\n",
    "        tissLst.append(i)\n",
    "yeti.saveLst(tissLst,'TissueDatasets.txt')\n",
    "\n",
    "timeLst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Time Points'])>2:\n",
    "        timeLst.append(i)\n",
    "yeti.saveLst(timeLst,'TimeDatasets.txt')\n",
    "\n",
    "trainLst=[]\n",
    "for i in dataDf.index:\n",
    "    if len(dataDf.at[i,'Trainings'])>1:\n",
    "        trainLst.append(i)\n",
    "yeti.saveLst(tissLst,'TrainingsDatasets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdbid\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dbid' is not defined"
     ]
    }
   ],
   "source": [
    "dbid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:126: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87db34b50f84a228ddc26c38276fa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=77.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on GSE27536 HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Max retries exceeded with url: /geo/query/acc.cgi?acc=GSE27536 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f4530890748>: Failed to establish a new connection: [Errno 101] Network is unreachable',))\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a0ac02deb01f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minfoFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MacrophageExercise_DatasetsInfo.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataDf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetDataDf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfoFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfDict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-64b4cc8fa748>\u001b[0m in \u001b[0;36mgetDataDf\u001b[0;34m(dataFiles, save, saveName, confDict, verbose)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'GSE'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'E-MTAB'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'EMTAB'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'EMEXP'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'E-MEXP'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetGSEData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfDict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0mlst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mdfDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-64b4cc8fa748>\u001b[0m in \u001b[0;36mgetGSEData\u001b[0;34m(gse, confDict, verbose)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0murlBase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc='\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murlBase\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mnumSamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetNumSamplesGSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 144\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "infoFile='MacrophageExercise_DatasetsInfo.xlsx'\n",
    "dataDf=getDataDf(gses,save=True,saveName=infoFile,confDict=confDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumDict(lst):\n",
    "    allDict={}\n",
    "    for dic in lst:\n",
    "        for key,num in dic.items():\n",
    "            if not key is np.nan:\n",
    "                if type(key) is str:\n",
    "                    key=key.upper()\n",
    "                    if len(key)>0:\n",
    "                        key=key[0]\n",
    "                if key in allDict:\n",
    "                    allDict[key]+=num\n",
    "                else:\n",
    "                    allDict[key]=num\n",
    "    return allDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-MTAB-1788 ['MSL1', 'MSL2']\n",
      "GSE111555 ['MB2']\n",
      "GSE117525 ['M66']\n",
      "GSE120862 ['M5']\n",
      "GSE126296 ['M2', 'MUSCLE11']\n",
      "GSE140089 ['MUSL100']\n",
      "GSE144304 ['MUSL98']\n",
      "GSE155933 ['M002', 'MUSCLE3', 'M1-2']\n",
      "GSE165630 ['M28']\n",
      "GSE1786 ['M47']\n",
      "GSE19062 ['M55']\n",
      "GSE19420 ['M72']\n",
      "GSE198266 ['MUSL104']\n",
      "GSE199225 ['M35']\n",
      "GSE236600 ['MUSL18']\n",
      "GSE23697 ['M56']\n",
      "GSE252357 ['MUSL97']\n",
      "GSE28422 ['M58']\n",
      "GSE28498 ['MB3']\n",
      "GSE33603 ['M41']\n",
      "GSE41769 ['M17']\n",
      "GSE44051 ['M23', 'MUSCLE7']\n",
      "GSE46075 ['MB4']\n",
      "GSE51216 ['MB6']\n",
      "GSE53598 ['M13']\n",
      "GSE59363 ['M44']\n",
      "GSE68585 ['M45']\n",
      "GSE72462 ['M52']\n",
      "GSE83352 ['M73']\n",
      "GSE8479 ['M71']\n",
      "GSE97084 ['M75']\n"
     ]
    }
   ],
   "source": [
    "lst=yeti.readLst('AgesDatasets.txt')\n",
    "for i in lst:\n",
    "    print(i,getDatasetIdFromSource(i,confDict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
